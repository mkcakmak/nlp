{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ba9e089-7328-42bd-b88c-62c979e17514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Alicia -\n",
      "PROPN\n",
      "proper noun\n",
      "NNP\n",
      "noun, proper singular \n",
      "\n",
      "- and -\n",
      "CCONJ\n",
      "coordinating conjunction\n",
      "CC\n",
      "conjunction, coordinating \n",
      "\n",
      "- me -\n",
      "PRON\n",
      "pronoun\n",
      "PRP\n",
      "pronoun, personal \n",
      "\n",
      "- went -\n",
      "VERB\n",
      "verb\n",
      "VBD\n",
      "verb, past tense \n",
      "\n",
      "- to -\n",
      "ADP\n",
      "adposition\n",
      "IN\n",
      "conjunction, subordinating or preposition \n",
      "\n",
      "- the -\n",
      "DET\n",
      "determiner\n",
      "DT\n",
      "determiner \n",
      "\n",
      "- school -\n",
      "NOUN\n",
      "noun\n",
      "NN\n",
      "noun, singular or mass \n",
      "\n",
      "- by -\n",
      "ADP\n",
      "adposition\n",
      "IN\n",
      "conjunction, subordinating or preposition \n",
      "\n",
      "- bus -\n",
      "NOUN\n",
      "noun\n",
      "NN\n",
      "noun, singular or mass \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "doc = nlp(\"Alicia and me went to the school by bus\")\n",
    "for token in doc:\n",
    "    print(\"-\",token.text,\"-\")\n",
    "    print(token.pos_)\n",
    "    print(spacy.explain(token.pos_))\n",
    "    print(token.tag_)\n",
    "    print(spacy.explain(token.tag_,),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01047bf4-0ab1-4701-a780-ed7412c58ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- My - PRON PRP$ pronoun pronoun, possessive\n",
      "- friend - NOUN NN noun noun, singular or mass\n",
      "- will - AUX MD auxiliary verb, modal auxiliary\n",
      "- fly - VERB VB verb verb, base form\n",
      "- to - ADP IN adposition conjunction, subordinating or preposition\n",
      "- New - PROPN NNP proper noun noun, proper singular\n",
      "- York - PROPN NNP proper noun noun, proper singular\n",
      "- fast - ADV RB adverb adverb\n",
      "- and - CCONJ CC coordinating conjunction conjunction, coordinating\n",
      "- she - PRON PRP pronoun pronoun, personal\n",
      "- is - AUX VBZ auxiliary verb, 3rd person singular present\n",
      "- staying - VERB VBG verb verb, gerund or present participle\n",
      "- there - ADV RB adverb adverb\n",
      "- for - ADP IN adposition conjunction, subordinating or preposition\n",
      "- 3 - NUM CD numeral cardinal number\n",
      "- days - NOUN NNS noun noun, plural\n",
      "- . - PUNCT . punctuation punctuation mark, sentence closer\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "doc = nlp(\"My friend will fly to New York fast and she is staying there for 3 days.\")\n",
    "\n",
    "for token in doc:\n",
    "    print(\"-\",token.text,\"-\",token.pos_,token.tag_,spacy.explain(token.pos_), spacy.explain(token.tag_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5c214508-14a2-4e1a-b1db-55b7d0c5d12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- My - PRON PRP$ pronoun pronoun, possessive\n",
      "- cat - NOUN NN noun noun, singular or mass\n",
      "- will - AUX MD auxiliary verb, modal auxiliary\n",
      "- fish - VERB VB verb verb, base form\n",
      "- for - ADP IN adposition conjunction, subordinating or preposition\n",
      "- a - DET DT determiner determiner\n",
      "- fish - NOUN NN noun noun, singular or mass\n",
      "- tomorrow - NOUN NN noun noun, singular or mass\n",
      "- in - ADP IN adposition conjunction, subordinating or preposition\n",
      "- a - DET DT determiner determiner\n",
      "- fishy - ADJ JJ adjective adjective (English), other noun-modifier (Chinese)\n",
      "- way - NOUN NN noun noun, singular or mass\n",
      "- . - PUNCT . punctuation punctuation mark, sentence closer\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "doc = nlp(\"My cat will fish for a fish tomorrow in a fishy way.\")\n",
    "for token in doc:\n",
    "    print(\"-\",token.text,\"-\",token.pos_, token.tag_, spacy.explain(token.pos_), spacy.explain(token.tag_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9fc3212e-733f-4b1e-867a-ac085b596226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- He - PRON PRP pronoun pronoun, personal\n",
      "- earned - VERB VBD verb verb, past tense\n",
      "- $ - SYM $ symbol symbol, currency\n",
      "- 5.5 - NUM CD numeral cardinal number\n",
      "- million - NUM CD numeral cardinal number\n",
      "- in - ADP IN adposition conjunction, subordinating or preposition\n",
      "- 2020 - NUM CD numeral cardinal number\n",
      "- and - CCONJ CC coordinating conjunction conjunction, coordinating\n",
      "- paid - VERB VBD verb verb, past tense\n",
      "- % - NOUN NN noun noun, singular or mass\n",
      "- 35 - NUM CD numeral cardinal number\n",
      "- tax - NOUN NN noun noun, singular or mass\n",
      "- . - PUNCT . punctuation punctuation mark, sentence closer\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "doc = nlp(\"He earned $5.5 million in 2020 and paid %35 tax.\")\n",
    "for token in doc:\n",
    "    print(\"-\",token.text,\"-\", token.pos_, token.tag_, spacy.explain(token.pos_), spacy.explain(token.tag_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1bd7d14b-e5fb-4230-b8d6-676fbc4366b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[('flying', 'fly')]\n",
      "[('fly', 'fly')]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "sent1 = \"I flew to Rome\"\n",
    "sent2 = \"I'm flying to Rome.\"\n",
    "sent3 = \"I will fly to Rome.\"\n",
    "doc1 = nlp(sent1)\n",
    "doc2 = nlp(sent2)\n",
    "doc3 = nlp(sent3)\n",
    "\n",
    "for doc in [doc1,doc2,doc3]:\n",
    "    print([(w.text, w.lemma_) for w in doc if w.tag_== 'VBG' or w.tag_== 'VB'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "90d9c1c0-04e5-403b-a766-461e91c5ae27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flying fly\n",
      "fly fly\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "sent1 = \"I flew to Rome\"\n",
    "sent2 = \"I'm flying to Rome.\"\n",
    "sent3 = \"I will fly to Rome.\"\n",
    "doc1 = nlp(sent1)\n",
    "doc2 = nlp(sent2)\n",
    "doc3 = nlp(sent3)\n",
    "\n",
    "for doc in [doc1,doc2,doc3]:\n",
    "    for token in doc:\n",
    "        if token.tag_==\"VBG\" or token.tag_==\"VB\" :\n",
    "            print(token.text,token.lemma_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d36dc471-38c2-4034-91ca-d7bc97fe124a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blue amod\n",
      "flower ROOT\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "doc = nlp(\"blue flower\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text,token.dep_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "293daea8-c4a0-4c0e-b21c-d1e1ef228587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', 'PRON', 'nsubj', counted), ('counted', 'VERB', 'ROOT', counted), ('white', 'ADJ', 'amod', sheep), ('sheep', 'NOUN', 'dobj', counted)]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "doc = nlp(\"I counted white sheep\")\n",
    "\n",
    "print([(token.text,token.pos_,token.dep_, token.head) for token in doc])    #second way for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bd62cc1-9fdb-4060-b91a-ad67260aeeff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- I - nsubj counted\n",
      "- counted - ROOT counted\n",
      "- white - amod sheep\n",
      "- sheep - dobj counted\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "doc = nlp(\"I counted white sheep\")\n",
    "\n",
    "for token in doc:\n",
    "    print(\"-\",token.text,\"-\",token.dep_,token.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e2be5f0-1458-43e9-9849-def40996b954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Donald Trump, France)\n",
      "France\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "doc = nlp(\"The president Donald Trump visited France.\")\n",
    "print(doc.ents)\n",
    "print(doc.ents[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6247e335-24d1-4ffa-bade-6126bed2c3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Companies, agencies, institutions, etc.\n"
     ]
    }
   ],
   "source": [
    "print(spacy.explain(\"ORG\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f73616a9-c7d1-424d-b325-926996437b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORG : Companies, agencies, institutions, etc.\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"He worked for NASA\")\n",
    "\n",
    "token = doc[3]\n",
    "print(token.ent_type_, \":\", spacy.explain(token.ent_type_))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d26e23a3-0efc-4197-af13-15afbfea1d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Albert Einstein, Ulm, 1987, ETH Zurich)\n",
      "Albert : PERSON People, including fictional\n",
      "Einstein : PERSON People, including fictional\n",
      "was :  None\n",
      "born :  None\n",
      "in :  None\n",
      "Ulm : GPE Countries, cities, states\n",
      "on :  None\n",
      "1987 : DATE Absolute or relative dates or periods\n",
      ". :  None\n",
      "He :  None\n",
      "studied :  None\n",
      "electronical :  None\n",
      "engineering :  None\n",
      "at :  None\n",
      "ETH : ORG Companies, agencies, institutions, etc.\n",
      "Zurich : ORG Companies, agencies, institutions, etc.\n",
      ". :  None\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Albert Einstein was born in Ulm on 1987. He studied electronical engineering at ETH Zurich.\")\n",
    "print(doc.ents)\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text,\":\",token.ent_type_,spacy.explain(token.ent_type_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33ed6f66-6d86-4ab4-ae5c-c3aae8f53f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Albert Einstein, Ulm, 1987, ETH Zurich)\n",
      "[('Albert', 'PERSON', 'People, including fictional'), ('Einstein', 'PERSON', 'People, including fictional'), ('was', '', None), ('born', '', None), ('in', '', None), ('Ulm', 'GPE', 'Countries, cities, states'), ('on', '', None), ('1987', 'DATE', 'Absolute or relative dates or periods'), ('.', '', None), ('He', '', None), ('studied', '', None), ('electronical', '', None), ('engineering', '', None), ('at', '', None), ('ETH', 'ORG', 'Companies, agencies, institutions, etc.'), ('Zurich', 'ORG', 'Companies, agencies, institutions, etc.'), ('.', '', None)]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Albert Einstein was born in Ulm on 1987. He studied electronical engineering at ETH Zurich.\")\n",
    "\n",
    "print(doc.ents)\n",
    "\n",
    "print([(token.text,token.ent_type_,spacy.explain(token.ent_type_)) for token in doc])   #second way for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f0b647d6-2a80-4da6-98e6-644b1b04a34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(New Hampshire,)\n",
      "[('She', 0, 'she'), ('lived', 1, 'live'), ('in', 2, 'in'), ('New', 3, 'New'), ('Hampshire', 4, 'Hampshire'), ('.', 5, '.')]\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "doc = nlp(\"She lived in New Hampshire.\")\n",
    "print(doc.ents)\n",
    "print([(token.text,token.i,token.lemma_) for token in doc])    ## Before Retokenizer \n",
    "print(len(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "89b290e7-b89c-42f0-bae3-838846574288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(New Hampshire,)\n",
      "[('She', 0), ('lived', 1), ('in', 2), ('New Hampshire', 3), ('.', 4)]\n",
      "5\n",
      "['she', 'live', 'in', 'new hampshire', '.']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "doc = nlp(\"She lived in New Hampshire.\")\n",
    "\n",
    "with doc.retokenize() as retokenizer:\n",
    "    retokenizer.merge(doc[3:5], attrs={\"LEMMA\":\"new hampshire\"})\n",
    "\n",
    "print(doc.ents)\n",
    "print([(token.text, token.i) for token in doc])                   ## After Retokenizer \n",
    "print(len(doc))\n",
    "print([(token.lemma_) for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f697e338-8911-4976-845d-c47fce474eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "[('She', 'she', 0), ('lived', 'live', 1), ('in', 'in', 2), ('NewHampshire', 'NewHampshire', 3), ('.', '.', 4)]\n",
      "She : PRON PRP nsubj\n",
      "lived : VERB VBD ROOT\n",
      "in : ADP IN prep\n",
      "NewHampshire : PROPN NNP pobj\n",
      ". : PUNCT . punct\n",
      "6\n",
      "[('She', 'she', 0), ('lived', 'live', 1), ('in', 'in', 2), ('New', 'New', 3), ('Hampshire', 'Hampshire', 4), ('.', '.', 5)]\n",
      "She PRON PRP nsubj\n",
      "lived VERB VBD ROOT\n",
      "in ADP IN prep\n",
      "New PROPN NNP compound\n",
      "Hampshire PUNCT NNP pobj\n",
      ". PUNCT . punct\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "doc = nlp(\"She lived in NewHampshire.\")\n",
    "print(len(doc))\n",
    "print([(token.text, token.lemma_,token.i) for token in doc])\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text,\":\",token.pos_,token.tag_, token.dep_)\n",
    "\n",
    "with doc.retokenize() as retokenizer:\n",
    "    heads = [(doc[3], 1), doc[2]]         #if you give a relative position (such as (doc[3], 1)) in the following code segment, this means that head of doc[3] will be the +1th position token—that is, doc[4] in the new setup\n",
    "    attrs = {\"TAG\":[\"NNP\", \"NNP\"], \"DEP\":[\"compound\", \"pobj\"]}\n",
    "    retokenizer.split(doc[3], [\"New\", \"Hampshire\"], heads=heads, attrs=attrs)\n",
    "    \n",
    "print(len(doc))\n",
    "print([(token.text, token.lemma_, token.i) for token in doc])\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.tag_, token.dep_)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
